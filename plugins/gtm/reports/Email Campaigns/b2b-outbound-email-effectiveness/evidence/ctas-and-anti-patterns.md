# Evidence: CTAs, Closing Techniques & Anti-Patterns

**Dimensions:** 5 (CTAs & Closing), 11 (Anti-Patterns)
**Date:** 2026-02-06
**Sources:** Gong Labs (304K emails + 28M emails), 30MPC/Gong (85M emails), Lavender AI, Josh Braun, Unbounce, GetResponse (756 emails received), GTMnow, Kyle Coleman

---

## Key sources referenced
- Gong Labs (304K email CTA study + 28M email analysis) — largest controlled CTA study
- 30MPC/Gong (85M emails) — pitching impact, ROI language, compelling offer effect
- Lavender / Will Allred (~200M emails) — reading level, "call to conversation" concept
- Josh Braun — "poke the bear" CTA, PS line strategies, no-CTA hypothesis
- Unbounce — single vs multi-CTA click-through study
- GetResponse (756 emails received, 2025) — recipient-side analysis of anti-patterns
- GTMnow — "10 Phrases to Avoid When Emailing Executives"
- Kyle Coleman — three-tier offer framework (Blind Date, 1:Many, 1:1)

---

## Findings

### Finding: Interest-based CTAs are 2x more effective than meeting-request CTAs
**Confidence:** CONFIRMED
**Evidence:** Gong Labs, 304,174 emails — accessed 2026-02-06

- Interest CTA: 12% reply rate, 68% positive replies, 15% meeting conversion
- Time-request CTA: 7% reply rate, 41% positive replies
- On 1,000 emails/month: ~82 positive conversations (interest) vs ~29 (time-request)
- IMPORTANT: For IN-DEAL emails, specific CTAs (day/time) double meetings booked (37% vs 15%).

**Implications:** Default interest-based for cold first-touch ("Worth exploring?"). Reserve calendar requests for warm follow-ups after interest expressed.

---

### Finding: Single CTA outperforms multiple CTAs by 371%
**Confidence:** CONFIRMED
**Evidence:** Unbounce study, Wordstream, Tarvent, Campaign Monitor — accessed 2026-02-06

- Single-CTA: +371% clicks, +1,617% sales vs multi-CTA.
- Choice overload causes inaction: more options = more confusion = no reply.
- "One email = one job."

**Implications:** Exactly one ask per cold email. No calendar links + case study PDFs + referral requests.

---

### Finding: Compelling offers increase reply rates by 28% beyond basic interest CTAs
**Confidence:** CONFIRMED
**Evidence:** 30MPC/Gong (85M emails), Kyle Coleman — accessed 2026-02-06

- Three offer tiers: (1) "Blind Date" — position who they'll meet, (2) "1:Many" — reusable insights/benchmarks, (3) "1:1" — custom audit/teardown.
- Interest-only ("Open to learning more?") shows modest improvement.
- Adding tangible offer on top = +28% reply rate.

**Implications:** "Can I send you the benchmark report on [metric]?" beats "Worth exploring?" by 28%. Build a library of 1:Many offers.

---

### Finding: "Thoughts?" as CTA increases replies but DECREASES meetings by 20%
**Confidence:** CONFIRMED
**Evidence:** Gong/30MPC — accessed 2026-02-06

- "What are your thoughts?" gets replies but not meetings.
- Positions you as seeking validation, not as authority.
- "Never heard back" decreases meetings by 14%.

**Implications:** Avoid "thoughts?" — it generates polite declines, not pipeline. Ask about interest in a specific outcome instead.

---

### Finding: PS lines capture attention via Zeigarnik effect — best for "poking the bear" or future-pacing
**Confidence:** INFERRED
**Evidence:** Josh Braun, psychological research on Zeigarnik effect — accessed 2026-02-06

- Josh Braun's four PS strategies: (1) "Poke the Bear" — provocative question, (2) "Future Pacing" — imagine better outcome, (3) "Make a Deposit" — share useful info, (4) "Leverage a Testimonial."
- "Most people read the PS line first before reading anything else."
- No controlled A/B data isolating PS line impact.

**Implications:** PS lines are underused. Best for reinforcing CTA or adding complementary hook. Keep to one sentence max.

---

### Finding: "Just following up" and "quick chat" are the most overused and least effective phrases
**Confidence:** CONFIRMED
**Evidence:** GetResponse (756 received emails, 2025), GTMnow, Gong — accessed 2026-02-06

- GetResponse: "Quick chat" appeared 145 times in 756 emails. "Just following up" appeared 59 times.
- Gong: "Never heard back" = -14% meetings. Mentioning voicemails = no positive impact.
- GTMnow exec research — phrases that kill credibility:
  - "I know you're busy, but..."
  - "Hope you're doing well!" (perceived as emotionally manipulative)
  - "Can I get 15 minutes of your time?"
  - "I was hoping to..." / "I just wanted to..." (passive, lacks confidence)
  - "Pick your brain" (signals vague meeting)
  - "Not sure if you saw my previous email..."

**Implications:** Eliminate these from all templates. Every follow-up must add new value. Replace passive language with direct phrasing.

---

### Finding: Emails over 125 words and wall-of-text formatting cost ~40% of replies
**Confidence:** CONFIRMED
**Evidence:** Gong, Lavender, howlongshouldacoldemailbe.com — accessed 2026-02-06

- Under 125 words: nearly double the response rate of longer.
- Same message as wall of text vs 3 clean paragraphs: 40% reply rate difference.
- Three-paragraph structure: 52% higher replies than single-paragraph.
- On mobile (67% first reads), a 2-line desktop paragraph = 4-5 mobile lines.

**Implications:** 50-100 words, 2-3 short paragraphs with whitespace. Preview on mobile before sending.

---

### Finding: Links, images, and tracking pixels hurt deliverability and reduce replies by 10-15%
**Confidence:** CONFIRMED
**Evidence:** MailMonitor, Persana AI, Instantly, Warmforge — accessed 2026-02-06

- Tracking pixels: -10% to -15% reply rate correlation.
- Links in first cold emails: flagged by spam filters.
- Gmail blocks 99.9% of spam using AI (content quality + user engagement analysis).
- Only 13% of cold emails in GetResponse study had clear text-based CTAs.

**Implications:** First email = pure plain text. No images, links, calendar embeds. "Reply to this email" is inherently safe.

---

### Finding: Over-personalization triggers "creep factor"; AI emails detectable by 61%
**Confidence:** CONFIRMED
**Evidence:** BuzzLead (2025), SuperRep AI, SalesHandy — accessed 2026-02-06

- Mentioning personal details (school, hobbies) before product pitch feels forced and creepy.
- Generic praise ("loved your work") when clearly copy-pasted triggers opposite reaction.
- 61.4% of consumers believe they can identify AI-generated cold emails.
- 44.4% less likely to engage with obviously AI-produced content.
- Hyper-targeted lists of 50-200 outperform mass blasts of 1,000+.

**Implications:** 1-2 specific, relevant details max. Only praise specifics. AI needs human editing.

---

### Finding: The "no-ask" email is an emerging hypothesis — unproven but provocative
**Confidence:** UNCERTAIN
**Evidence:** Josh Braun (LinkedIn, May 2024) — accessed 2026-02-06

- Braun: "Cold email CTAs aren't necessary. People don't have to be called to action. CTAs sound needy."
- Counterpoint: Signposting desired action increases response even when action is clear.
- No controlled A/B data at scale.

**Implications:** Frontier hypothesis. For most teams, keep soft CTA. Could work for executive-level prospects turned off by any "salesy" feel.

---

### Finding: Irrelevant social proof and name-dropping backfire
**Confidence:** CONFIRMED
**Evidence:** Gong/30MPC (85M emails) — accessed 2026-02-06

- Social proof +41% only when relevant to recipient.
- Dropping Fortune 500 names to 50-person startup signals misunderstanding.
- Relevance hierarchy: prospect sees themselves in the example.
- One line of relevant proof > paragraph of irrelevant name drops.

**Implications:** Match social proof to prospect's company size, role, and industry.

---

## Negative searches

- "Two option close cold email data effectiveness" — No cold email-specific controlled studies.
- "PS line cold email A/B test data reply rate" — No quantitative A/B studies found.
- "CTA placement end vs middle cold email controlled study" — Conflicting advice, no definitive data.

---

## Gaps / follow-ups

- PS line impact needs controlled A/B testing
- "No-ask" email hypothesis needs quantitative validation
- CTA placement (end vs middle) has no definitive answer
- Tone calibration (formal vs casual) lacks granular data
